{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anD278SFrdps",
    "outputId": "cb4d3e19-0f9e-408b-9c02-78fe67d4ba38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 0.1 - General Purpose Libraries/Modules\n",
    "\n",
    "# for linear algebra\n",
    "import numpy as np\n",
    "# for data processing and file I/O\n",
    "import pandas as pd\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# for measuring latency\n",
    "import time\n",
    "\n",
    "# for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# for balancing the loss function (the dataset is imbalanced)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import  XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# for evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W4tXGwCasx6n"
   },
   "outputs": [],
   "source": [
    "# 0.2 - The CNN architecture is implemented via keras\n",
    "\n",
    "# basic configuration\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# for the implemantation of the models\n",
    "from keras import layers, Sequential\n",
    "\n",
    "# for readability purposes\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Reshape, Concatenate, Conv2D, GlobalAveragePooling2D\n",
    "from keras.layers import Input,BatchNormalization, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "# for the customization of the model and the training process\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hP95abHETYnE"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y2XBODIUeUXO"
   },
   "outputs": [],
   "source": [
    "def get_feature_importances_rf (_data, _target):\n",
    "  RFC = RandomForestClassifier(random_state=10, n_jobs=1) # 100 trees in forest\n",
    "  RFC.fit(_data, _target)\n",
    "  score = np.round(RFC.feature_importances_,5)\n",
    "  _importances = pd.DataFrame({'features':_data.columns,'level of importance':score})\n",
    "  _importances = _importances.sort_values('level of importance',ascending=False).set_index('features')\n",
    "  return _importances\n",
    "\n",
    "\n",
    "def get_feature_importances_xgb(_data, _target):\n",
    "  XGB = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, missing=np.inf)\n",
    "  XGB.fit(_data, _target)\n",
    "  score = np.round(XGB.feature_importances_,5)\n",
    "  _importances = pd.DataFrame({'features':_data.columns,'level of importance':score})\n",
    "  _importances = _importances.sort_values('level of importance',ascending=False).set_index('features')\n",
    "  return _importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TNFPF9TUtmIx"
   },
   "outputs": [],
   "source": [
    "# Custom F1-Score Metric\n",
    "class F1ScoreMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1ScoreMetric, self).__init__(name=name, **kwargs)\n",
    "        self.precision = self.add_weight(name='precision', initializer='zeros')\n",
    "        self.recall = self.add_weight(name='recall', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(tf.greater_equal(y_pred, 0.5), tf.int32)\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "\n",
    "        tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "        fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "        fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "\n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "        self.precision.assign(precision)\n",
    "        self.recall.assign(recall)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision\n",
    "        recall = self.recall\n",
    "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.assign(0)\n",
    "        self.recall.assign(0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
